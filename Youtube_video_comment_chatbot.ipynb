{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "gpuType": "T4",
      "mount_file_id": "1cq52c0y3o6PSrheCOoYVPaAMld5gUuiO",
      "authorship_tag": "ABX9TyNHUKpHu4PJwaGadOIJSJvw",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/GuanRuLai/Python-project-Youtube-Video-Comment-Chatbot/blob/main/Youtube_video_comment_chatbot.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Install necessary libraries"
      ],
      "metadata": {
        "id": "ABJN1At4ojI8"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y2nqq6K4hNS6",
        "outputId": "5f9aed03-59c3-42ad-8ae3-c371576e3a9c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain in /usr/local/lib/python3.10/dist-packages (0.3.14)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (6.0.2)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.36)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.11.11)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.3)\n",
            "Requirement already satisfied: langchain-core<0.4.0,>=0.3.29 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.3.29)\n",
            "Requirement already satisfied: langchain-text-splitters<0.4.0,>=0.3.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.3.4)\n",
            "Requirement already satisfied: langsmith<0.3,>=0.1.17 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.2.10)\n",
            "Requirement already satisfied: numpy<2,>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.26.4)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.10.4)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.32.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (9.0.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (24.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.18.3)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.29->langchain) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.29->langchain) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.29->langchain) (4.12.2)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.3,>=0.1.17->langchain) (0.28.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.3,>=0.1.17->langchain) (3.10.13)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.3,>=0.1.17->langchain) (1.0.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.27.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2024.12.14)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.1.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.3,>=0.1.17->langchain) (3.7.1)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.3,>=0.1.17->langchain) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.3,>=0.1.17->langchain) (0.14.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.29->langchain) (3.0.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.3,>=0.1.17->langchain) (1.3.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.3,>=0.1.17->langchain) (1.2.2)\n",
            "Collecting langchain_openai\n",
            "  Downloading langchain_openai-0.2.14-py3-none-any.whl.metadata (2.7 kB)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (13.9.4)\n",
            "Requirement already satisfied: langchain-core<0.4.0,>=0.3.27 in /usr/local/lib/python3.10/dist-packages (from langchain_openai) (0.3.29)\n",
            "Requirement already satisfied: openai<2.0.0,>=1.58.1 in /usr/local/lib/python3.10/dist-packages (from langchain_openai) (1.59.3)\n",
            "Collecting tiktoken<1,>=0.7 (from langchain_openai)\n",
            "  Downloading tiktoken-0.8.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich) (2.18.0)\n",
            "Requirement already satisfied: typing-extensions<5.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from rich) (4.12.2)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.27->langchain_openai) (6.0.2)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.27->langchain_openai) (1.33)\n",
            "Requirement already satisfied: langsmith<0.3,>=0.1.125 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.27->langchain_openai) (0.2.10)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.27->langchain_openai) (24.2)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.5.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.27->langchain_openai) (2.10.4)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.27->langchain_openai) (9.0.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich) (0.1.2)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.58.1->langchain_openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.58.1->langchain_openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.58.1->langchain_openai) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.58.1->langchain_openai) (0.8.2)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.58.1->langchain_openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.58.1->langchain_openai) (4.67.1)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken<1,>=0.7->langchain_openai) (2024.11.6)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken<1,>=0.7->langchain_openai) (2.32.3)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.58.1->langchain_openai) (3.10)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.58.1->langchain_openai) (1.2.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.58.1->langchain_openai) (2024.12.14)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.58.1->langchain_openai) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai<2.0.0,>=1.58.1->langchain_openai) (0.14.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.27->langchain_openai) (3.0.0)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.3,>=0.1.125->langchain-core<0.4.0,>=0.3.27->langchain_openai) (3.10.13)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.3,>=0.1.125->langchain-core<0.4.0,>=0.3.27->langchain_openai) (1.0.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.5.2->langchain-core<0.4.0,>=0.3.27->langchain_openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.5.2->langchain-core<0.4.0,>=0.3.27->langchain_openai) (2.27.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken<1,>=0.7->langchain_openai) (3.4.1)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken<1,>=0.7->langchain_openai) (2.3.0)\n",
            "Downloading langchain_openai-0.2.14-py3-none-any.whl (50 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tiktoken-0.8.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m66.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: tiktoken, langchain_openai\n",
            "Successfully installed langchain_openai-0.2.14 tiktoken-0.8.0\n",
            "Collecting youtube_search\n",
            "  Downloading youtube_search-2.1.2-py3-none-any.whl.metadata (1.2 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from youtube_search) (2.32.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->youtube_search) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->youtube_search) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->youtube_search) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->youtube_search) (2024.12.14)\n",
            "Downloading youtube_search-2.1.2-py3-none-any.whl (3.4 kB)\n",
            "Installing collected packages: youtube_search\n",
            "Successfully installed youtube_search-2.1.2\n",
            "Collecting yt-dlp\n",
            "  Downloading yt_dlp-2024.12.23-py3-none-any.whl.metadata (172 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m172.1/172.1 kB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading yt_dlp-2024.12.23-py3-none-any.whl (3.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m77.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: yt-dlp\n",
            "Successfully installed yt-dlp-2024.12.23\n",
            "Collecting faiss-gpu\n",
            "  Downloading faiss_gpu-1.7.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.4 kB)\n",
            "Downloading faiss_gpu-1.7.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (85.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.5/85.5 MB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: faiss-gpu\n",
            "Successfully installed faiss-gpu-1.7.2\n",
            "Collecting langchain-community\n",
            "  Downloading langchain_community-0.3.14-py3-none-any.whl.metadata (2.9 kB)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (6.0.2)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (2.0.36)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (3.11.11)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain-community)\n",
            "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
            "Collecting httpx-sse<0.5.0,>=0.4.0 (from langchain-community)\n",
            "  Downloading httpx_sse-0.4.0-py3-none-any.whl.metadata (9.0 kB)\n",
            "Requirement already satisfied: langchain<0.4.0,>=0.3.14 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (0.3.14)\n",
            "Requirement already satisfied: langchain-core<0.4.0,>=0.3.29 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (0.3.29)\n",
            "Requirement already satisfied: langsmith<0.3,>=0.1.125 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (0.2.10)\n",
            "Requirement already satisfied: numpy<2,>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (1.26.4)\n",
            "Collecting pydantic-settings<3.0.0,>=2.4.0 (from langchain-community)\n",
            "  Downloading pydantic_settings-2.7.1-py3-none-any.whl.metadata (3.5 kB)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (2.32.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (9.0.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.3.2)\n",
            "Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (4.0.3)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (24.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.18.3)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
            "  Downloading marshmallow-3.24.2-py3-none-any.whl.metadata (7.1 kB)\n",
            "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: langchain-text-splitters<0.4.0,>=0.3.3 in /usr/local/lib/python3.10/dist-packages (from langchain<0.4.0,>=0.3.14->langchain-community) (0.3.4)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.10/dist-packages (from langchain<0.4.0,>=0.3.14->langchain-community) (2.10.4)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.29->langchain-community) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.29->langchain-community) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.29->langchain-community) (4.12.2)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.3,>=0.1.125->langchain-community) (0.28.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.3,>=0.1.125->langchain-community) (3.10.13)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.3,>=0.1.125->langchain-community) (1.0.0)\n",
            "Collecting python-dotenv>=0.21.0 (from pydantic-settings<3.0.0,>=2.4.0->langchain-community)\n",
            "  Downloading python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain-community) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain-community) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain-community) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain-community) (2024.12.14)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain-community) (3.1.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.3,>=0.1.125->langchain-community) (3.7.1)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.3,>=0.1.125->langchain-community) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.3,>=0.1.125->langchain-community) (0.14.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.29->langchain-community) (3.0.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<0.4.0,>=0.3.14->langchain-community) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<0.4.0,>=0.3.14->langchain-community) (2.27.2)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.3,>=0.1.125->langchain-community) (1.3.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.3,>=0.1.125->langchain-community) (1.2.2)\n",
            "Downloading langchain_community-0.3.14-py3-none-any.whl (2.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m68.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
            "Downloading httpx_sse-0.4.0-py3-none-any.whl (7.8 kB)\n",
            "Downloading pydantic_settings-2.7.1-py3-none-any.whl (29 kB)\n",
            "Downloading marshmallow-3.24.2-py3-none-any.whl (49 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.3/49.3 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
            "Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Installing collected packages: python-dotenv, mypy-extensions, marshmallow, httpx-sse, typing-inspect, pydantic-settings, dataclasses-json, langchain-community\n",
            "Successfully installed dataclasses-json-0.6.7 httpx-sse-0.4.0 langchain-community-0.3.14 marshmallow-3.24.2 mypy-extensions-1.0.0 pydantic-settings-2.7.1 python-dotenv-1.0.1 typing-inspect-0.9.0\n"
          ]
        }
      ],
      "source": [
        "!pip install langchain\n",
        "!pip install langchain_openai rich\n",
        "!pip install youtube_search\n",
        "!pip install yt-dlp\n",
        "!pip install faiss-gpu\n",
        "!pip install langchain-community"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import libraries"
      ],
      "metadata": {
        "id": "2RAvzAzHo1ev"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from google.colab import userdata\n",
        "from langchain_community.tools import YouTubeSearchTool\n",
        "from yt_dlp import YoutubeDL\n",
        "from openai import OpenAI\n",
        "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
        "from langchain_community.vectorstores import FAISS\n",
        "from langchain_openai import OpenAIEmbeddings\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_core.runnables import RunnablePassthrough\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain_core.prompts import MessagesPlaceholder\n",
        "from langchain.tools.retriever import create_retriever_tool\n",
        "from langchain.agents import AgentExecutor, create_openai_tools_agent\n",
        "from langchain_community.chat_message_histories import SQLChatMessageHistory\n",
        "from langchain_core.runnables.history import RunnableWithMessageHistory"
      ],
      "metadata": {
        "id": "lqOcO9eeo4PS"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Set api key"
      ],
      "metadata": {
        "id": "JLhvOfldq3t2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ[\"OPENAI_API_KEY\"] = userdata.get(\"OPENAI_API_KEY\")"
      ],
      "metadata": {
        "id": "DXkYDSaZq6lE"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# define a function for getting the url of the video"
      ],
      "metadata": {
        "id": "5s4Fek0nqoUy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def search_url(query):\n",
        "  tool = YouTubeSearchTool() # Build Youtube tool object\n",
        "  result = tool.invoke(query + \",1\")\n",
        "  urls = eval(result) # Parse the string into a Python expression\n",
        "  urls = [url.split(\"&\")[0] for url in urls]\n",
        "\n",
        "  return urls"
      ],
      "metadata": {
        "id": "yIFSTu4RqqLQ"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Define a function for downloading the the audio of the video"
      ],
      "metadata": {
        "id": "mVXqIaZRsYLy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def url_download(url):\n",
        "    try:\n",
        "        # Set output file name\n",
        "        drive_path = \"/content/drive/MyDrive/Colab Notebooks/人工智慧-深度學習/深度學習模型實作/生成式 AI\"\n",
        "        output_path = os.path.join(drive_path, \"audio\")\n",
        "\n",
        "        # yt-dlp options for downloading audio\n",
        "        ydl_opts = {\n",
        "            'format': 'bestaudio/best', # Download the best quality audio\n",
        "            'outtmpl': output_path,\n",
        "            'postprocessors': [{\n",
        "                'key': 'FFmpegExtractAudio', # Extract audio\n",
        "                'preferredcodec': 'mp3', # Convert to mp3\n",
        "                'preferredquality': '192', # Audio quality\n",
        "            }],\n",
        "        }\n",
        "\n",
        "        # Download the audio\n",
        "        with YoutubeDL(ydl_opts) as ydl:\n",
        "            print(f\"開始下載: {url}\")\n",
        "            ydl.download([url])\n",
        "            print(\"音訊下載成功\")\n",
        "    except Exception as e:\n",
        "        print(f\"下載過程中出現錯誤: {e}\")"
      ],
      "metadata": {
        "id": "Mo5w9_6Dsaim"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Define a function for ASR using OpenAI Whisper API"
      ],
      "metadata": {
        "id": "eTwIhNbqsop5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def audio_to_text(file_path):\n",
        "  client = OpenAI()\n",
        "  audio_file = open(file_path, \"rb\")\n",
        "  transcript = client.audio.transcriptions.create(\n",
        "      model=\"whisper-1\",\n",
        "      file=audio_file\n",
        "    )\n",
        "\n",
        "  return transcript.text"
      ],
      "metadata": {
        "id": "1EZ-hoZMsrBT"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Define a function for data processing & RAG chain building"
      ],
      "metadata": {
        "id": "v7cD2fGQs0s_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def rag(text):\n",
        "  # split the data\n",
        "  text_splitter = RecursiveCharacterTextSplitter(separators=[\" \"], # Slice on a word basis\n",
        "                                               chunk_size=300, # Maximum size of each cut text block\n",
        "                                               chunk_overlap=20) # Overlap between adjacent text blocks(make sure there is some context)\n",
        "  splits = text_splitter.split_text(text)\n",
        "\n",
        "  # convert text to vector & store into vector database\n",
        "  embeddings = OpenAIEmbeddings(model=\"text-embedding-3-large\")\n",
        "  db = FAISS.from_texts(splits, embeddings)\n",
        "  db.save_local(\"/content/drive/MyDrive/Colab Notebooks/人工智慧-深度學習/深度學習模型實作/生成式 AI/youtube_db\")\n",
        "\n",
        "  new_db = FAISS.load_local(\n",
        "      folder_path=\"/content/drive/MyDrive/Colab Notebooks/人工智慧-深度學習/深度學習模型實作/生成式 AI/youtube_db\",\n",
        "      embeddings=embeddings,\n",
        "      allow_dangerous_deserialization=True)\n",
        "\n",
        "  chat_model = ChatOpenAI(model=\"gpt-4o-mini\")\n",
        "\n",
        "  str_parser = StrOutputParser()\n",
        "\n",
        "  # Creates a retriever tool for fetching relevant video content based on queries\n",
        "  retriever = new_db.as_retriever()\n",
        "\n",
        "  tool = create_retriever_tool(\n",
        "      retriever=retriever,\n",
        "      name=\"retriever_tool\",\n",
        "      description=\"檢索並返回文字相關資訊\"\n",
        "  )\n",
        "\n",
        "  tools = [tool]\n",
        "\n",
        "  # Create agent\n",
        "  agent_prompt = ChatPromptTemplate.from_messages([\n",
        "      (\"system\", \"你是一位善用工具的好助理, 請仔細判斷上下文來回答問題, 盡量以文字內容 RAG 功能優先\"),\n",
        "      MessagesPlaceholder(variable_name=\"chat_history\"),\n",
        "      (\"human\", \"{input}\"),\n",
        "      MessagesPlaceholder(variable_name=\"agent_scratchpad\")\n",
        "  ])\n",
        "\n",
        "  agent = create_openai_tools_agent(llm=chat_model,\n",
        "                                    tools=tools,\n",
        "                                    prompt=agent_prompt)\n",
        "\n",
        "  agent_executor = AgentExecutor(agent=agent,\n",
        "                                 tools=tools,\n",
        "                                 verbose=False) # The system won't show whether it use the tool or not\n",
        "\n",
        "  # Store chat messages history\n",
        "  memory = SQLChatMessageHistory(\n",
        "      session_id=\"test_id\",\n",
        "      connection_string=\"sqlite:////content/drive/MyDrive/Colab Notebooks/人工智慧-深度學習/深度學習模型實作/生成式 AI/retriever.db\"\n",
        "  )\n",
        "\n",
        "  # Limit the chat memory to the latest six messages for context clarity\n",
        "  def window_messages(chain_input):\n",
        "      if len(memory.messages) > 6:\n",
        "          cur_messages = memory.messages\n",
        "          memory.clear()\n",
        "          for message in cur_messages[-6:]:\n",
        "              memory.add_message(message)\n",
        "      return None\n",
        "\n",
        "  # Integrate chat history into the agent's execution for consistent interaction\n",
        "  def add_history(agent_executor):\n",
        "      agent_with_chat_history = RunnableWithMessageHistory(\n",
        "          agent_executor,\n",
        "          lambda session_id: memory,\n",
        "          input_messages_key=\"input\",\n",
        "          history_messages_key=\"chat_history\",\n",
        "      )\n",
        "      memory_chain = (\n",
        "          RunnablePassthrough.assign(messages=window_messages)\n",
        "          | agent_with_chat_history\n",
        "      )\n",
        "      return memory_chain\n",
        "\n",
        "  return add_history(agent_executor)"
      ],
      "metadata": {
        "id": "6JXxV-Ejs2Sd"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Main program"
      ],
      "metadata": {
        "id": "u76S-K38u3HU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "while True:\n",
        "    msg = input(\"請問您要查詢的影片關鍵字是？：\")\n",
        "    if not msg.strip():\n",
        "        break\n",
        "\n",
        "    urls = search_url(msg)\n",
        "    print(urls)\n",
        "    url_download(urls[0])\n",
        "    print(\"處理中，請稍後...\")\n",
        "    text = audio_to_text(\"/content/drive/MyDrive/Colab Notebooks/人工智慧-深度學習/深度學習模型實作/生成式 AI/audio.mp3\")\n",
        "    print(\"處理完畢，可以開始進行問答！\")\n",
        "\n",
        "    memory_chain = rag(text)\n",
        "    if memory_chain is None:\n",
        "      print(\"無法建立記憶鏈，請檢查輸入資料。\")\n",
        "      continue\n",
        "\n",
        "    while True:\n",
        "        msg = input(\"我的問題：\")\n",
        "        if not msg.strip():\n",
        "            break\n",
        "        for chunk in memory_chain.stream(\n",
        "            {\"input\": msg},\n",
        "            config={\"configurable\": {\"session_id\": \"test_id\"}}):\n",
        "            if \"output\" in chunk:\n",
        "                print(f\"AI 回覆：{chunk['output']}\", end=\"\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ftHymvoxu5vS",
        "outputId": "b44ce63b-f3f7-45e5-9b4a-143135be4f31"
      },
      "execution_count": 11,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "請問您要查詢的影片關鍵字是？：邱軍\n",
            "['https://www.youtube.com/watch?v=DIKkgjxnzRk']\n",
            "開始下載: https://www.youtube.com/watch?v=DIKkgjxnzRk\n",
            "[youtube] Extracting URL: https://www.youtube.com/watch?v=DIKkgjxnzRk\n",
            "[youtube] DIKkgjxnzRk: Downloading webpage\n",
            "[youtube] DIKkgjxnzRk: Downloading ios player API JSON\n",
            "[youtube] DIKkgjxnzRk: Downloading mweb player API JSON\n",
            "[youtube] DIKkgjxnzRk: Downloading m3u8 information\n",
            "[info] DIKkgjxnzRk: Downloading 1 format(s): 251\n",
            "[download] Destination: /content/drive/MyDrive/Colab Notebooks/人工智慧-深度學習/深度學習模型實作/生成式 AI/audio\n",
            "[download] 100% of    1.56MiB in 00:00:00 at 15.41MiB/s  \n",
            "[ExtractAudio] Destination: /content/drive/MyDrive/Colab Notebooks/人工智慧-深度學習/深度學習模型實作/生成式 AI/audio.mp3\n",
            "Deleting original file /content/drive/MyDrive/Colab Notebooks/人工智慧-深度學習/深度學習模型實作/生成式 AI/audio (pass -k to keep)\n",
            "音訊下載成功\n",
            "處理中，請稍後...\n",
            "處理完畢，可以開始進行問答！\n",
            "我的問題：請問剛剛下載的內容是關於什麼？\n",
            "AI 回覆：剛剛下載的內容是關於一起交通事故的報導，涉及歌手邱君。事件發生在去年12月27日，邱君駕駛的車輛在基隆市撞上了一名計程車司機，該司機在搶救一週後宣告死亡。報導中提到事故後邱君未停車並拒絕接聽電話，最終兩天後才現身，並表示因忙碌無法及時到案。警方已展開調查，並將邱君列為公共危險及逃逸等罪嫌，案件正在進一步偵辦中。我的問題：請問我剛剛問什麼？\n",
            "AI 回覆：您剛剛詢問的是關於這位歌手一夕之間從歌手變成殺人犯的情況，我提供了對此事件的看法和相關的觀點。我的問題：我說前一個問題我問什麼？\n",
            "AI 回覆：您前一個問題是「請問剛剛下載的內容是關於什麼？」我的問題：請問你對於此情況的看法，給我三個面向。\n",
            "AI 回覆：對於這起交通事故的情況，可以從以下三個面向進行分析：\n",
            "\n",
            "1. **法律責任**：\n",
            "   - 在此事件中，邱君的行為可能涉及公共危險和逃逸的法律問題。若證實其在事故後未停車並拒絕配合調查，這可能會導致更嚴重的法律後果。法律上應該如何處理這類事件，將會影響公眾對於法律公正的信任。\n",
            "\n",
            "2. **社會影響**：\n",
            "   - 這起事件引發了社會對於名人責任的討論。名人作為公眾人物，應具備更高的社會責任感，其行為對社會有較大的影響。社會大眾可能對於名人在面對法律問題時的態度和行為感到失望，進而影響其形象和事業發展。\n",
            "\n",
            "3. **心理健康與媒體報導**：\n",
            "   - 事件中的當事者可能面臨巨大的心理壓力，尤其是在事件曝光後，公眾的評價和媒體的報導可能加劇其心理負擔。此外，媒體在報導此類事件時的方式也會影響公眾的看法，應注意如何平衡報導的真實性與對當事者的尊重和同情。\n",
            "\n",
            "這三個面向提供了對於事件的不同角度的理解，有助於全面評估事件的影響及後果。我的問題：謝謝\n",
            "AI 回覆：不客氣！如果您還有其他問題或需要進一步的幫助，隨時告訴我！我的問題：\n",
            "請問您要查詢的影片關鍵字是？：\n"
          ]
        }
      ]
    }
  ]
}